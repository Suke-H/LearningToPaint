{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hzwer/LearningToPaint/blob/master/LearningToPaint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFN3oT1Hkjfs"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/hzwer/LearningToPaint.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dp7N29tGkwQs"
   },
   "outputs": [],
   "source": [
    "# cd LearningToPaint/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTbhmFyawzhO"
   },
   "source": [
    "Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0wTTzOEbvps"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-02 17:28:31--  https://drive.google.com/uc?export=download&id=1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4\n",
      "drive.google.com (drive.google.com) をDNSに問いあわせています... 142.250.206.206, 2404:6800:400a:813::200e\n",
      "drive.google.com (drive.google.com)|142.250.206.206|:443 に接続しています... 接続しました。\n",
      "HTTP による接続要求を送信しました、応答を待っています... 302 Moved Temporarily\n",
      "場所: https://doc-0o-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qjq8nmv2n8aha57hh1jp81f5veg18omv/1633163250000/10102393604162075786/*/1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4?e=download [続く]\n",
      "警告: HTTPはワイルドカードに対応していません。\n",
      "--2021-10-02 17:28:34--  https://doc-0o-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qjq8nmv2n8aha57hh1jp81f5veg18omv/1633163250000/10102393604162075786/*/1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4?e=download\n",
      "doc-0o-58-docs.googleusercontent.com (doc-0o-58-docs.googleusercontent.com) をDNSに問いあわせています... 142.250.206.225, 2404:6800:400a:804::2001\n",
      "doc-0o-58-docs.googleusercontent.com (doc-0o-58-docs.googleusercontent.com)|142.250.206.225|:443 に接続しています... 接続しました。\n",
      "HTTP による接続要求を送信しました、応答を待っています... 200 OK\n",
      "長さ: 特定できません [application/octet-stream]\n",
      "`renderer.pkl' に保存中\n",
      "\n",
      "renderer.pkl            [     <=>            ]  42.12M  51.8MB/s    時間 0.8s    \n",
      "\n",
      "2021-10-02 17:28:36 (51.8 MB/s) - `renderer.pkl' へ保存終了 [44165821]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://drive.google.com/uc?export=download&id=1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4\" -O renderer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pfd53Hw2cfaY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-02 17:28:39--  https://drive.google.com/uc?export=download&id=1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR\n",
      "drive.google.com (drive.google.com) をDNSに問いあわせています... 142.250.206.206, 2404:6800:400a:813::200e\n",
      "drive.google.com (drive.google.com)|142.250.206.206|:443 に接続しています... 接続しました。\n",
      "HTTP による接続要求を送信しました、応答を待っています... 302 Moved Temporarily\n",
      "場所: https://doc-0c-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/blnvnhn2o1recsb4ocqsaqg2e1p9507h/1633163250000/10102393604162075786/*/1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR?e=download [続く]\n",
      "警告: HTTPはワイルドカードに対応していません。\n",
      "--2021-10-02 17:28:41--  https://doc-0c-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/blnvnhn2o1recsb4ocqsaqg2e1p9507h/1633163250000/10102393604162075786/*/1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR?e=download\n",
      "doc-0c-58-docs.googleusercontent.com (doc-0c-58-docs.googleusercontent.com) をDNSに問いあわせています... 142.250.206.225, 2404:6800:400a:804::2001\n",
      "doc-0c-58-docs.googleusercontent.com (doc-0c-58-docs.googleusercontent.com)|142.250.206.225|:443 に接続しています... 接続しました。\n",
      "HTTP による接続要求を送信しました、応答を待っています... 200 OK\n",
      "長さ: 特定できません [application/octet-stream]\n",
      "`actor.pkl' に保存中\n",
      "\n",
      "actor.pkl               [    <=>             ]  42.82M  60.1MB/s    時間 0.7s    \n",
      "\n",
      "2021-10-02 17:28:43 (60.1 MB/s) - `actor.pkl' へ保存終了 [44898539]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://drive.google.com/uc?export=download&id=1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR\" -O actor.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZpb3_3QiMZw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-02 17:28:46--  https://raw.githubusercontent.com/hzwer/LearningToPaint/master/image/Trump.png\n",
      "raw.githubusercontent.com (raw.githubusercontent.com) をDNSに問いあわせています... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443 に接続しています... 接続しました。\n",
      "HTTP による接続要求を送信しました、応答を待っています... 200 OK\n",
      "長さ: 36916 (36K) [image/png]\n",
      "`image/test.png' に保存中\n",
      "\n",
      "image/test.png      100%[===================>]  36.05K  --.-KB/s    時間 0.005s  \n",
      "\n",
      "2021-10-02 17:28:47 (6.73 MB/s) - `image/test.png' へ保存完了 [36916/36916]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -U NoSuchBrowser/1.0 -O image/test.png https://raw.githubusercontent.com/hzwer/LearningToPaint/master/image/Trump.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brX4ZlQoc9ss"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canvas step 0, L2Loss = 0.024947304278612137\n",
      "canvas step 1, L2Loss = 0.015929289162158966\n",
      "canvas step 2, L2Loss = 0.01127323042601347\n",
      "canvas step 3, L2Loss = 0.009232412092387676\n",
      "canvas step 4, L2Loss = 0.008130980655550957\n",
      "canvas step 5, L2Loss = 0.007595773786306381\n",
      "canvas step 6, L2Loss = 0.007106195669621229\n",
      "canvas step 7, L2Loss = 0.0067121610045433044\n",
      "canvas step 8, L2Loss = 0.006311751902103424\n",
      "canvas step 9, L2Loss = 0.005904891528189182\n",
      "canvas step 10, L2Loss = 0.005597099661827087\n",
      "canvas step 11, L2Loss = 0.005431695841252804\n",
      "canvas step 12, L2Loss = 0.005231333896517754\n",
      "canvas step 13, L2Loss = 0.005060245282948017\n",
      "canvas step 14, L2Loss = 0.004901556298136711\n",
      "canvas step 15, L2Loss = 0.004688805900514126\n",
      "canvas step 16, L2Loss = 0.00453956937417388\n",
      "canvas step 17, L2Loss = 0.004488827660679817\n",
      "canvas step 18, L2Loss = 0.004353329539299011\n",
      "canvas step 19, L2Loss = 0.004266673699021339\n",
      "canvas step 20, L2Loss = 0.0042082080617547035\n",
      "canvas step 21, L2Loss = 0.004071112722158432\n",
      "canvas step 22, L2Loss = 0.003969218116253614\n",
      "canvas step 23, L2Loss = 0.003912771120667458\n",
      "canvas step 24, L2Loss = 0.0037841990124434233\n",
      "canvas step 25, L2Loss = 0.003696110565215349\n",
      "canvas step 26, L2Loss = 0.003647721139714122\n",
      "canvas step 27, L2Loss = 0.0035668066702783108\n",
      "canvas step 28, L2Loss = 0.003548160195350647\n",
      "canvas step 29, L2Loss = 0.003486892208456993\n",
      "canvas step 30, L2Loss = 0.0034479666501283646\n",
      "canvas step 31, L2Loss = 0.003401451511308551\n",
      "canvas step 32, L2Loss = 0.0033219538163393736\n",
      "canvas step 33, L2Loss = 0.00330007029697299\n",
      "canvas step 34, L2Loss = 0.0032131995540112257\n",
      "canvas step 35, L2Loss = 0.003154774196445942\n",
      "canvas step 36, L2Loss = 0.0031278077512979507\n",
      "canvas step 37, L2Loss = 0.0030694601591676474\n",
      "canvas step 38, L2Loss = 0.0030469789635390043\n",
      "canvas step 39, L2Loss = 0.003018453251570463\n",
      "divided canvas step 0, L2Loss = 0.0017954254290089011\n",
      "divided canvas step 1, L2Loss = 0.0013129047583788633\n",
      "divided canvas step 2, L2Loss = 0.0010717336554080248\n",
      "divided canvas step 3, L2Loss = 0.0009342347038909793\n",
      "divided canvas step 4, L2Loss = 0.0008445364655926824\n",
      "divided canvas step 5, L2Loss = 0.0007717463304288685\n",
      "divided canvas step 6, L2Loss = 0.0007147393771447241\n",
      "divided canvas step 7, L2Loss = 0.00066914944909513\n",
      "divided canvas step 8, L2Loss = 0.0006362030981108546\n",
      "divided canvas step 9, L2Loss = 0.0006048697978258133\n",
      "divided canvas step 10, L2Loss = 0.000574173522181809\n",
      "divided canvas step 11, L2Loss = 0.0005525711458176374\n",
      "divided canvas step 12, L2Loss = 0.0005321860662661493\n",
      "divided canvas step 13, L2Loss = 0.0005075273802503943\n",
      "divided canvas step 14, L2Loss = 0.0004922907683067024\n",
      "divided canvas step 15, L2Loss = 0.0004746090853586793\n",
      "divided canvas step 16, L2Loss = 0.0004606774600688368\n",
      "divided canvas step 17, L2Loss = 0.0004483025404624641\n",
      "divided canvas step 18, L2Loss = 0.00044092177995480597\n",
      "divided canvas step 19, L2Loss = 0.0004327415954321623\n",
      "divided canvas step 20, L2Loss = 0.000425298378104344\n",
      "divided canvas step 21, L2Loss = 0.0004183560668025166\n",
      "divided canvas step 22, L2Loss = 0.0004122311365790665\n",
      "divided canvas step 23, L2Loss = 0.00040500357863493264\n",
      "divided canvas step 24, L2Loss = 0.00039648651727475226\n",
      "divided canvas step 25, L2Loss = 0.0003910765517503023\n",
      "divided canvas step 26, L2Loss = 0.00038681007572449744\n",
      "divided canvas step 27, L2Loss = 0.0003800109261646867\n",
      "divided canvas step 28, L2Loss = 0.00037550361594185233\n",
      "divided canvas step 29, L2Loss = 0.0003719761152751744\n",
      "divided canvas step 30, L2Loss = 0.000367413682397455\n",
      "divided canvas step 31, L2Loss = 0.00036230171099305153\n",
      "divided canvas step 32, L2Loss = 0.00035747408401221037\n",
      "divided canvas step 33, L2Loss = 0.0003545633517205715\n",
      "divided canvas step 34, L2Loss = 0.000349278561770916\n",
      "divided canvas step 35, L2Loss = 0.00034497049637138844\n",
      "divided canvas step 36, L2Loss = 0.0003398897242732346\n",
      "divided canvas step 37, L2Loss = 0.0003357655950821936\n",
      "divided canvas step 38, L2Loss = 0.0003328845195937902\n",
      "divided canvas step 39, L2Loss = 0.00032687056227587163\n"
     ]
    }
   ],
   "source": [
    "!python3 baseline/test.py --max_step=80 --actor=actor.pkl --renderer=renderer.pkl --img=image/test.png --divide=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLM4U6F0_yjV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg: error while loading shared libraries: libopenh264.so.5: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -r 30 -f image2 -i output/generated%d.png -s 512x512 -c:v libx264 -pix_fmt yuv420p video.mp4 -q:v 0 -q:a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekY7HcBeh8zl"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No ffmpeg exe could be found. Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c35912f14bba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'video.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/generated399.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/moviepy/editor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Clips\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoFileClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageSequenceClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageSequenceClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_webfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/moviepy/video/io/VideoFileClip.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioFileClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioFileClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDEVNULL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m from ..decorators import (add_mask_if_none, apply_to_mask,\n\u001b[1;32m     20\u001b[0m                           \u001b[0mconvert_masks_to_RGB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_seconds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/moviepy/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mFFMPEG_BINARY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'ffmpeg-imageio'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_exe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mFFMPEG_BINARY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_exe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mFFMPEG_BINARY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'auto-detect'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36mget_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mimageio_ffmpeg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimageio_ffmpeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ffmpeg_exe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/imageio_ffmpeg/_utils.py\u001b[0m in \u001b[0;36mget_ffmpeg_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Nothing was found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     raise RuntimeError(\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;34m\"No ffmpeg exe could be found. Install ffmpeg on your system, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;34m\"or set the IMAGEIO_FFMPEG_EXE environment variable.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No ffmpeg exe could be found. Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable."
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "import moviepy.editor as mpy\n",
    "display(mpy.ipython_display('video.mp4', height=256, max_duration=100.))\n",
    "display(Image('output/generated399.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2mAkgRjwwuf"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-p0NhqyTqO_"
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXAV9RwkTwKh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/honda/デスクトップ/LearningToPaint/data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzZUVjdrET2G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: gdown: コマンドが見つかりません\n"
     ]
    }
   ],
   "source": [
    "# !gdown https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgguAW3eETVd"
   },
   "outputs": [],
   "source": [
    "# !unzip img_align_celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBH--DY-sK8V"
   },
   "outputs": [],
   "source": [
    "# !rm img_align_celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6mVpjvBvzrb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/honda/デスクトップ/LearningToPaint\n"
     ]
    }
   ],
   "source": [
    "cd デスクトップ/LearningToPaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-PYJVt8pc6BP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████▉                    | 998/2000 [01:36<01:35, 10.45it/s]step: 1000, saved model\n",
      "100%|██████████████████████████████████████▉| 1999/2000 [03:13<00:00, 10.43it/s]step: 2000, saved model\n",
      "100%|███████████████████████████████████████| 2000/2000 [03:13<00:00, 10.33it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 baseline/train_renderer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZWjNmD23gKm"
   },
   "outputs": [],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehnzhWn9GG4I"
   },
   "outputs": [],
   "source": [
    "%%writefile baseline/env.py\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from DRL.ddpg import decode\n",
    "from utils.util import *\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "aug = transforms.Compose(\n",
    "            [transforms.ToPILImage(),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "             ])\n",
    "\n",
    "width = 128\n",
    "convas_area = width * width\n",
    "\n",
    "img_train = []\n",
    "img_test = []\n",
    "train_num = 0\n",
    "test_num = 0\n",
    "\n",
    "class Paint:\n",
    "    def __init__(self, batch_size, max_step):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_step = max_step\n",
    "        self.action_space = (13)\n",
    "        self.observation_space = (self.batch_size, width, width, 7)\n",
    "        self.test = False\n",
    "        \n",
    "    def load_data(self):\n",
    "        # CelebA\n",
    "        global train_num, test_num\n",
    "        for i in range(200000):\n",
    "            img_id = '%06d' % (i + 1)\n",
    "            try:\n",
    "                img = cv2.imread('./data/img_align_celeba/' + img_id + '.jpg', cv2.IMREAD_UNCHANGED)\n",
    "                img = cv2.resize(img, (width, width))\n",
    "                if i > 2000:                \n",
    "                    train_num += 1\n",
    "                    img_train.append(img)\n",
    "                else:\n",
    "                    test_num += 1\n",
    "                    img_test.append(img)\n",
    "            finally:\n",
    "                if (i + 1) % 10000 == 0:                    \n",
    "                    print('loaded {} images'.format(i + 1))\n",
    "        print('finish loading data, {} training images, {} testing images'.format(str(train_num), str(test_num)))\n",
    "        \n",
    "    def pre_data(self, id, test):\n",
    "        if test:\n",
    "            img = img_test[id]\n",
    "        else:\n",
    "            img = img_train[id]\n",
    "        if not test:\n",
    "            img = aug(img)\n",
    "        img = np.asarray(img)\n",
    "        return np.transpose(img, (2, 0, 1))\n",
    "    \n",
    "    def reset(self, test=False, begin_num=False):\n",
    "        self.test = test\n",
    "        self.imgid = [0] * self.batch_size\n",
    "        self.gt = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n",
    "        for i in range(self.batch_size):\n",
    "            if test:\n",
    "                id = (i + begin_num)  % test_num\n",
    "            else:\n",
    "                id = np.random.randint(train_num)\n",
    "            self.imgid[i] = id\n",
    "            self.gt[i] = torch.tensor(self.pre_data(id, test))\n",
    "        self.tot_reward = ((self.gt.float() / 255) ** 2).mean(1).mean(1).mean(1)\n",
    "        self.stepnum = 0\n",
    "        self.canvas = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n",
    "        self.lastdis = self.ini_dis = self.cal_dis()\n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        # canvas B * 3 * width * width\n",
    "        # gt B * 3 * width * width\n",
    "        # T B * 1 * width * width\n",
    "        ob = []\n",
    "        T = torch.ones([self.batch_size, 1, width, width], dtype=torch.uint8) * self.stepnum\n",
    "        return torch.cat((self.canvas, self.gt, T.to(device)), 1) # canvas, img, T\n",
    "\n",
    "    def cal_trans(self, s, t):\n",
    "        return (s.transpose(0, 3) * t).transpose(0, 3)\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.canvas = (decode(action, self.canvas.float() / 255) * 255).byte()\n",
    "        self.stepnum += 1\n",
    "        ob = self.observation()\n",
    "        done = (self.stepnum == self.max_step)\n",
    "        reward = self.cal_reward() # np.array([0.] * self.batch_size)\n",
    "        return ob.detach(), reward, np.array([done] * self.batch_size), None\n",
    "\n",
    "    def cal_dis(self):\n",
    "        return (((self.canvas.float() - self.gt.float()) / 255) ** 2).mean(1).mean(1).mean(1)\n",
    "    \n",
    "    def cal_reward(self):\n",
    "        dis = self.cal_dis()\n",
    "        reward = (self.lastdis - dis) / (self.ini_dis + 1e-8)\n",
    "        self.lastdis = dis\n",
    "        return to_numpy(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0kwVmo6yv1w3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 10000 images\n",
      "loaded 20000 images\n",
      "loaded 30000 images\n",
      "loaded 40000 images\n",
      "loaded 50000 images\n",
      "loaded 60000 images\n",
      "loaded 70000 images\n",
      "loaded 80000 images\n",
      "loaded 90000 images\n",
      "loaded 100000 images\n",
      "loaded 110000 images\n",
      "loaded 120000 images\n",
      "loaded 130000 images\n",
      "loaded 140000 images\n",
      "loaded 150000 images\n",
      "loaded 160000 images\n",
      "loaded 170000 images\n",
      "loaded 180000 images\n",
      "loaded 190000 images\n",
      "loaded 200000 images\n",
      "finish loading data, 197999 training images, 2001 testing images\n",
      "observation_space (96, 128, 128, 7) action_space 13\n",
      "/home/honda/デスクトップ/LearningToPaint/baseline/env.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  self.gt[i] = torch.tensor(self.pre_data(id, test))\n",
      "\u001b[98m #0: steps:200 interval_time:6.09 train_time:0.00\u001b[00m\n",
      "\u001b[98m #1: steps:400 interval_time:5.56 train_time:0.00\u001b[00m\n",
      "Traceback (most recent call last):\n",
      "  File \"baseline/train.py\", line 117, in <module>\n",
      "    train(agent, fenv, evaluate)\n",
      "  File \"baseline/train.py\", line 40, in train\n",
      "    action = agent.select_action(observation, noise_factor=noise_factor)\n",
      "  File \"/home/honda/デスクトップ/LearningToPaint/baseline/DRL/ddpg.py\", line 177, in select_action\n",
      "    action = self.play(state)\n",
      "  File \"/home/honda/デスクトップ/LearningToPaint/baseline/DRL/ddpg.py\", line 85, in play\n",
      "    return self.actor(state)\n",
      "  File \"/home/honda/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/honda/デスクトップ/LearningToPaint/baseline/DRL/actor.py\", line 105, in forward\n",
      "    x = F.relu(self.bn1(self.conv1(x)))\n",
      "  File \"/home/honda/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/honda/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\", line 131, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/honda/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py\", line 2056, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 10.92 GiB total capacity; 9.44 GiB already allocated; 92.62 MiB free; 9.79 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "# !python3 baseline/train.py --max_step=200 --debug --batch_size=96\n",
    "!python3 baseline/train.py --max_step=200 --debug --batch_size=96 --train_times=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "learningtopaint.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
